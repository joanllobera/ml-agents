{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design new environment\n",
    "\n",
    "## Roller Ball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training with editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scene SingleEnvironment is the one you are going to use in order to test and train your roller agent.\n",
    "It's already settup for you to press play and watch an already trained agent do some work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you want to train it yourself you need to follow the following steps:\n",
    "\n",
    "1. Duplicating and assigning a new brain to the agent\n",
    "Go to the folder \"Brains\" and duplicate the brain named \"RollerBallBrain\" and change its name to MyRollerBrain for example.\n",
    "\n",
    "Look for the \"RollerAgent\" gameObject and drag this new brain to the Brain parameter in the \"RollerAgentSingleInstance\" component.\n",
    "\n",
    "After that you will need to look for the \"Academy\" gameObject, look for the \"RollerAcademy\" component and click Add New in the Broadcast Hub section. Drag that same brain to the new space created in the Broadcast Hub and click the Control checkbox that appears next to it. This checkbox allows for external control of that brain in order to train, once trained you will need to uncheck this checkbox in order to see the result of the training.\n",
    "\n",
    "\n",
    "2. Starting the training\n",
    "You need a Anaconda Command Prompt opened and go, using the \"cd PATH\" command, to the base ml-agents folder. It will have a folder named config, UnitySDK, etc...\n",
    "Once in here run the following commands:\n",
    "--> activate ml-agents\n",
    "--> mlagents-learn config/trainer_config.yaml --run-id=314 --train\n",
    "You can change the \"314\" for any name you want, it will be the name of the file with the agent's training results.\n",
    "\n",
    "Once you enter that last command it will ask you to press the Play button in unity in order to start, press it and your agent will start training until done. When it is the console will stop writing allowing you to enter new commands, this means you are done training.\n",
    "\n",
    "3. Applying the results\n",
    "In the base folder of ml-agents you used for the cd command before there's a \"models\" folder. Enter it and you will find a folder with the name you put as the runID in the training command. Drag this folder to Unity asset folder.\n",
    "Once this is done you have to look for the brain you duplicated in the first step and look for the \"model\" parameter and drag the .bytes file inside that folder you dragged earlier.\n",
    "Lastly go to the Academy and uncheck that control checkbox next to YOUR brain like explained at the end of the first step.\n",
    "\n",
    "If everything was done correctly, at this point you should be able to press Play in the Unity Editor and see your agent move by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training with compiled environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training with compiled headless environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training with 16 environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tensorboard comparisons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
